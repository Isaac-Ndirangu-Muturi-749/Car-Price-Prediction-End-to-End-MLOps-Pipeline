{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install hyperopt xgboost mlflow boto3 -q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code sets up the hyperparameter tuning process using hyperopt, logs the parameters and metrics to MLflow, and runs the optimization. After running the optimization, you will be able to see the results in the MLflow UI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: Import Libraries and Suppress Warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://mlflow-artifacts-capstone-mlops/4', creation_time=1722115105130, experiment_id='4', last_update_time=1722115105130, lifecycle_stage='active', name='xgboost_hyperparameter_tuning', tags={}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "import xgboost as xgb\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Suppress specific warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='xgboost')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='_distutils_hack')\n",
    "\n",
    "# Set MLflow tracking URI\n",
    "EC2_PUBLIC_DNS='ec2-16-16-217-131.eu-north-1.compute.amazonaws.com'\n",
    "mlflow.set_tracking_uri(f\"http://{EC2_PUBLIC_DNS}:5000\")\n",
    "mlflow.set_experiment(\"xgboost_hyperparameter_tuning\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Load Data and Preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (86392, 19)\n",
      "Testing data shape: (21599, 19)\n",
      "First few rows of the scaled training data:\n",
      "[[ 0.9171049  -1.06487922  0.4380831  -1.8997133   2.4206718   3.05252791\n",
      "  -0.21935334 -0.24096514 -0.44371169 -0.21594036 -0.36700329 -0.24611195\n",
      "  -0.25485438 -0.37469737 -0.39570361 -1.1391218   1.83331115 -0.16062932\n",
      "   0.88124322]\n",
      " [-1.41870071  0.30215763 -2.09510711  1.04440611 -1.20361943 -0.32759733\n",
      "  -0.21935334 -0.24096514  2.25371569 -0.21594036 -0.36700329 -0.24611195\n",
      "  -0.25485438 -0.37469737 -0.39570361  0.87786925 -0.54546114 -0.16062932\n",
      "   0.88124322]\n",
      " [ 0.9171049  -0.96480263  0.35364342 -0.75735782 -0.84119031 -0.32759733\n",
      "  -0.21935334 -0.24096514 -0.44371169  4.63090817 -0.36700329 -0.24611195\n",
      "  -0.25485438 -0.37469737 -0.39570361  0.87786925 -0.54546114 -0.16062932\n",
      "   0.88124322]\n",
      " [ 0.9171049  -0.99095472  0.35364342  0.30141068 -1.20361943 -0.32759733\n",
      "  -0.21935334 -0.24096514 -0.44371169 -0.21594036 -0.36700329 -0.24611195\n",
      "   3.92380939 -0.37469737 -0.39570361  0.87786925 -0.54546114 -0.16062932\n",
      "   0.88124322]\n",
      " [-0.95153959  1.64271194 -1.75734841  1.1930052  -0.11633206 -0.32759733\n",
      "  -0.21935334 -0.24096514  2.25371569 -0.21594036 -0.36700329 -0.24611195\n",
      "  -0.25485438 -0.37469737 -0.39570361  0.87786925 -0.54546114 -0.16062932\n",
      "  -1.1347605 ]]\n"
     ]
    }
   ],
   "source": [
    "# Load the cleaned data\n",
    "cleaned_df = pd.read_csv('../data/cleaned_car_data.csv')\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "X = cleaned_df.drop(columns=['price'])  # Exclude 'price'\n",
    "y = cleaned_df['price']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the shape of the splits\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}\")\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Optional: Check the first few rows of the scaled data\n",
    "print(\"First few rows of the scaled training data:\")\n",
    "print(X_train_scaled[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: Define Hyperparameter Space and Objective Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'max_depth': hp.quniform('max_depth', 3, 10, 1),\n",
    "    'n_estimators': hp.quniform('n_estimators', 100, 1000, 100),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1.0),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
    "    'seed': 42,\n",
    "    'objective': 'reg:squarederror'\n",
    "}\n",
    "\n",
    "def objective(params):\n",
    "    with mlflow.start_run(nested=True):\n",
    "        # Convert hyperparameters to int if they are passed as floats\n",
    "        params[\"max_depth\"] = int(params[\"max_depth\"])\n",
    "        params[\"n_estimators\"] = int(params[\"n_estimators\"])\n",
    "\n",
    "        # Log hyperparameters\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # Train the model\n",
    "        model = xgb.XGBRegressor(\n",
    "            n_estimators=params[\"n_estimators\"],\n",
    "            max_depth=params[\"max_depth\"],\n",
    "            learning_rate=params[\"learning_rate\"],\n",
    "            subsample=params[\"subsample\"],\n",
    "            seed=params[\"seed\"],\n",
    "            objective=params[\"objective\"]\n",
    "        )\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "\n",
    "        # Predict and evaluate\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        rmse = root_mean_squared_error(y_test, y_pred)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.xgboost.log_model(model, \"model\")\n",
    "\n",
    "        return {'loss': rmse, 'status': STATUS_OK}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: Run Hyperparameter Optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [07:44<00:00,  9.30s/trial, best loss: 2285.035402316803]\n",
      "\n",
      "\n",
      "Best parameters: {'learning_rate': 0.09455111298980684, 'max_depth': 9.0, 'min_child_weight': 0.3730492049381335, 'n_estimators': 500.0, 'subsample': 0.9989341273723211}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best_params = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,  # Adjust this number based on how long you want to search\n",
    "    trials=trials\n",
    ")\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
